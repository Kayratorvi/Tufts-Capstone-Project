<html lang="en">
    <head>
        <meta name="viewport" content="width=device-width" charset="utf-8" initial-scale="1">
        <title>Weekly Status Report</title>
    </head>
    <body>
        <h1>Gavin Grooms's Master's Capstone Project<br>Weekly Status Report</h1>
        <h2>Sept. 10-16 Report</h2>
        <p>
            This week we had our first meetup with Prof. Allen where we discussed the structure of this capstone project. I also began to brainstorm project ideas, as up to this point I hadn't locked down any concrete ideas for what to build. Instead of coming up with one idea, I wrote down three to consider that I submitted in my project proposal. Here are the ideas:
            <ol>
            <li>
                I want to develop an app that can re-tune accompaniment music to fit your custom tuning or can even re-tune music based on MIDI input automatically.
            </li>

            <li>
                I could build an application to meet the needs of an exchange student management company. The app would securely manage forms, data, and applications, etc. in an organized manner using feedback from my parents who work in that industry.
            </li>
            
            <li>
                I want to develop an app/discord bot that would help me manage my Pokémon collecting in a much more organized manner. Currently you have to use separate apps for tracking a hunt, managing your collection, and looking up information on how a Pokémon is caught or the odds of catching a particular one. This app would combine everything in a seamless interface
            </li>
            </ol>
            Each one of these ideas has something uniquely appealing to me, which is why I included all three. The first idea is clearly the most challenging, and would require algorithms and the use of languages and libraries I have little to no experience with. It could end up only as a proof of concept, but it is exciting and combines my two degrees, Music Performane and Computer Science, which is really cool.
            <br><br>
            The second idea is a full product that I would develop that has potential as a marketable application. It would require the use of a lot of languages and infrastructure to build, as ideally I would have both a web application and a mobile app that are connected.
            <br><br>
            The third idea is much more of a fun idea, as I would be able to build something just for me. To be honest, I may build it even if it isn't my capstone project. It would be fun to try and come up with several ways to interface with the data that I want to manage.
            <br><br>
            Hopefully I will receive feedback soon on what might help me most in helping me start my career as a software engineer. It really depends on whether having a finished product or a more complex project is more important. 
        </p>
        <h2>Sept. 17-23 Report</h2>
        <p>
            This week I have been working on deciding what my project will be of the three ideas I submitted last week. So far, the favorite has been project idea #1, which is both exciting and daunting. I have much less confidence in my ability to build this project than I do with the other two ideas. That is however a good thing, as success in a more difficult endeavor will surely be more impressive to potential employers.
            <br><br>
            The problem is that further research into what it would take to build this project has revealed that I would need to build two complex components that both work with each other. It is far more likely that I would only have time to do one of them.
            <ul>
                <li>I would need an intonation interpreter, something that can listen to a .wav or .mp3 file and determine the tuning of each pitch in the file. MIDI does not store tuning data whatsoever and thus would not be sufficient alone.</li>
                <li>The other component would be to build a software synthesizer that can play a MIDI file while automatically adjusting to the tuning input from a user or from the previous component. I looked into a programming API called CSound which may assist greatly in completing this particular task.</li>
            </ul>
            Either one of these components would be fairly complex. While it would definitely be cool to learn to build either one or both, I'm definitely apprehensive concerning the task(s) at hand. I have no knowledge on any of the tools I would need to use, and a significant portion of this project would be spent on learning to use them. If I chose instead to implement one of my other ideas, I would be able to get started much sooner, as there wouldn't be nearly as much I would need to learn from scratch. It would be great to get some feedback on my concerns and on which project idea I should move forward with.
        </p>
        <h2>Sept. 24-30 Report</h2>
        <p>
            This week I outlined my project requirements, including what problem this project is meant to solve, what my solution is, and a high-level explanation of how I intend to implement the solution. Much of this is well explained in the README of my GitHub repository, which can be found <a href="https://github.com/Kayratorvi/Tufts-Capstone-Project">here</a>.
            <br><br>
            I met with Marty Allen during our biweekly meeting and presented my project requirements and was asked some valuable questions:
            <ul>
                <li>How do I prove that my project does what I say it does to someone with limited experience in music and intonation?</li>
                <li>What can I do to ensure that my ambitious project idea can be delivered in some completed form in May 2024?</li>
                <li>What kind of input should I expect users to provide? Is it too much to ask for users to provide MIDI files as input?</li>
                <li>Will I expect a live recording handled by my application, or will I expect a specific recording file format?</li>
            </ul>
            These are all important questions. I can verify the project's authenticity by using third-party tuners and verification from musicians I know that my project indeed retunes chords as defined in my project spec. I have also defined programming phases in my README that should guarantee an impressive, usable product that can be delivered as my capstone project. I also think it's reasonable to expect MIDI input as that is a growing medium that many college-level musicians have access to through their university benefits and education. I intend to answer the question of human recording later as I investigate various solutions.
            <br><br>
            I have approval to move forward with this project. I'm excited to see whether I am capable of success in such a challenging endeavor. If not, I do have a plan B project proposal involving a custom app for foreign exchange student management companies. This idea is not as exciting, but should still allow me the opportunity of building an application using many different tools, languages, and technologies.
        </p>
        <h2>Oct. 1-7 Report</h2>
        <p>
            This week I focused on researching existing libraries, APIs, and frameworks if any exist that might help facilitate my project. I discussed my project idea with my manager at my workplace, and he suggested I look into Audacity, which is an open-source audio editor. As it turns out, Audacity has full support for scripting in the Python language, and looks to have full capability for use as the synthesizer for my project. What this means is that I should be able to complete the first phase of this project using Audacity fairly quickly, allowing me to pursue the later phases of my project instead of spending all my time building a synthesizer from scratch.
            <br><br>
            My next step is to practice using Audacity enough to prove that it is fully capable of supporting my capstone project. This will be submitted as my Competency Demo. My plan is to write a small program that can retune 5 notes fed in from MIDI input. If I can do this, then the entirety of my first phase should be very doable. This will be my task for the coming week or so.
        </p>
        <h2>Oct. 8-14 Report</h2>
        <p>
            This week I started working with Audacity in testing its scripting abilities to determine whether it could be used as an API for my capstone project. Unfortunately, I found that while Audacity can produce tones with custom pitches, it's very barebones and lacks much of the functionality I would need to rely on Audacity alone as a synthesizer. There is still potential for its use as a mixer in helping me combine multiple tracks (computer generated input and the live instrument recording) however it is not a suitable resource for producing more complex synth sounds.
            I have a few open source synthesizers to investigate as I researched further for other options, including Amsynth, Zyn, and Yoshimi among others. Ideally it would be great to find an application that would allow me to write scripts to produce synthesized music, but I may very well end up needing to write the synthesizer myself instead. I'll update next week with my findings.
        </p>
        <h2>Oct. 15-21 Report</h2>
        <p>
            This week I spent all my time researching alternatives for use as a backend library to generate the notes and tones I need to build my synthesizer. It turned out that Amsynth, Zyn, Yoshimi, and Audacity all do not provide the APIs I need to generate my own sound from my own input. They all in some way act as mixers and can modify existing audio, and as programs only offered high-level interfaces that do not provide the tools I need. I decided I had to look at much lower-level libraries to find what I needed. I came across a library known as Nsound, which itself is built as an API for Csound. This is a low-level library that offers the ability to generate tones to be used for a myriad of purposes. Since Nsound is released using the GNU license, I should be able to use and/or modify it to my needs. Based on what I have read into it so far, I will still need to write a program to read from a MIDI file and then use Nsound to generate the tones to my preference and tuning. Most likely, this means my project will primarily be to write the synthesizer that my later proposed phases would need to rely on. I still should be able to use Python as my language of choice, as my understanding is that I should be able to interact with C++ libraries easily using Python. This coming week I plan to look into writing an example program using Nsound to hopefully demonstrate that it has the programming interfaces that I need to make my project a reality.
        </p>
        <h2>Oct. 22-28 Report</h2>
        <p>
            This week I started working with NSound to produce the computer generated tones that I would need to make my project a reality. It has turned out that this library will work great for my needs! It has built-in instruments that I can use and methods for easily adjusting intonation and note length. It should be sufficient for my needs as part of the backend that will support my capstone project. The only trouble I've run into, is that NSound is limited by computer hardware in how many tones it can produce simultaneously. Modern computers generally support two audio channels, and this is what the OS allows. Natively producing more than two tones at once will require either a specialized OS and hardware, or simply the addition of a mixer Python library to overlay .wav files together. I plan to research options starting with Audacity, which I found to be a mixer at its core to see if I can write a Python script to produce the tones and overlay them to produce a single audio .wav output file.
        </p>
        <h2>Oct. 29-Nov. 4 Report</h2>
        <p>
            The focus of this week was to prepare a script that utilizes NSound and a mixer library to demonstrate the output of a chord with three tones in one .wav file. Initially, I was set back by a large project that was due in my Intro to Security class, but I ended up successful even if it wasn't in the way I expected. While Audacity is a mixer and would work for what I intend to do in overlaying audio together, it is more difficult and clunky to use, requiring that the application be installed and open. This is not ideal for an end product that I wish to be able to install on lots of devices. I researched other options and came across the popular Pydub Python library, which has support for making adjustments to audio files including overlaying them to output one file. I have decided to go with this library in the end since it is easier to package together and use with my own scripts and will likely allow for easier distribution of an end product than anything dealing with Audacity. My plan for the coming week is to formally complete my competency demo for presentation before starting on my full design document and proof of concept demo. 
        </p>
        <h2>Nov. 5-11 Report</h2>
        <p>
            This week I met with Marty Allen again and discussed how to handle the submission of my competency demo and proof of concept demo, as they have basically melded into the same thing. I don't have much experience with Python, NSound, or any of the tools I'm using for my project, so I went ahead and worked on a proof of concept to also serve as proof that I am capable of working on the project in the first place. I am submitting both on Nov. 12 to Canvas. Since Zoom wouldn't include the audio from the two .wav files created during my demo, I am instead going to embed them inside this week's entry. They should both be below, 261 hz and 440 hz:
            <br>
            <audio controls>
                <source src="gavin_test_chord_261.wav" type="audio/wav">
                Your browser does not support the audio tag.
            </audio>
            <br>
            <audio controls>
            <source src="gavin_test_chord_440.wav" type="audio/wav">
            Your browser does not support the audio tag.
            </audio>
            <br>
            My next task is to work on a full design document before getting started on the actual implementation. I should be able to start implementation before the semester ends. 
        </p>
        <h2>Nov. 12-18 Report</h2>
        <p>
            This week I began working on my full implementation document. I want to make sure it's full of detail and leaves nothing out, so I'll likely finish sometime in the next week or so. With Thanksgiving this next week, I'll likely take that week off and finish the design document the following week, the last week of November. This should position me so that I'm ready to tackle the coding part of this capstone project head on beginning in December. I'm feeling pretty excited about the shape my project has taken and about my progress so far. The proof of concept demo helped me to more fully envision what this project will look like when it is completed. 
        </p> 
        <h2>Nov. 26-Dec. 2 Report</h2>
        <p>
            This week I submitted my full implementation plan. This included detailed writeups for all phases of my project, and I outlined how I would approach the beginning and end of each phase, as well as described the goals for each phase. I also talked about the tools I would be using, such as the Python libraries I'm working with, the data structures I plan to use, and what kinds of things I'll work with to test my program at each step. This is the final deliverable for this first semester, so I will wait for feedback and improve upon my implementation document if it is needed.
        </p>
        <h2>Dec. 3-9 Report</h2>
        <p>
            This week I got sick with a terrible chest cold, so even though I received feedback requesting for more specific details on my data structures and functions, I was not able to do much work this week and spent most of my time in bed.
        </p>
        <h2>Dec. 10-16 Report</h2>
        <p>
            This is the final week I plan to report on until after the New Year, as I plan to take the holiday time off to be with my family. This week I updated my implementation document with exact plans for each of my planned data structures, even going so far as to provide the code I would use to build each one. I also wrote a few Python functions to demonstrate how I plan to get my project to work in the first phase. This was accepted, so my deliverables for this first half of my capstone project are now completed to satisfaction. After the holiday break, I will begin work in earnest on the actual implementation itself. Merry Christmas and Happy New Year!
        </p>
    </body>
</html>